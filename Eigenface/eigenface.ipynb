{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# AML HW3 Problem 1",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ],
   "id": "2d20ab673c74ac52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (b)\n",
    "\n",
    "# Load training data\n",
    "train_labels, train_data = [], []\n",
    "\n",
    "with open('./faces/train.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        path, label = line.strip().split()\n",
    "        img = imageio.imread(path)\n",
    "        train_data.append(img.reshape(2500,))   # 50 x 50 = 2500\n",
    "        train_labels.append(int(label))\n",
    "\n",
    "train_data = np.array(train_data, dtype=float)\n",
    "train_labels = np.array(train_labels, dtype=int)\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "\n",
    "plt.imshow(train_data[10, :].reshape(50, 50), cmap=cm.Greys_r)\n",
    "plt.title(f\"Train sample, label={train_labels[10]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load test data\n",
    "test_labels, test_data = [], []\n",
    "\n",
    "with open('./faces/test.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        path, label = line.strip().split()\n",
    "        img = imageio.imread(path)\n",
    "        test_data.append(img.reshape(2500,))\n",
    "        test_labels.append(int(label))\n",
    "\n",
    "test_data = np.array(test_data, dtype=float)\n",
    "test_labels = np.array(test_labels, dtype=int)\n",
    "\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)\n",
    "\n",
    "plt.imshow(test_data[10, :].reshape(50, 50), cmap=cm.Greys_r)\n",
    "plt.title(f\"Test sample, label={test_labels[10]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "5fb1a18162c4a0bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (c)\n",
    "\n",
    "# Compute average face\n",
    "mu = np.mean(train_data, axis=0)\n",
    "print(\"Average face vector shape:\", mu.shape)\n",
    "\n",
    "plt.imshow(mu.reshape(50, 50), cmap=cm.Greys_r)\n",
    "plt.title(\"Average Face (Î¼)\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "800c32f7d81ff556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (d)\n",
    "\n",
    "# Mean subtraction for training data\n",
    "X_centered = train_data - mu\n",
    "\n",
    "plt.imshow(X_centered[10, :].reshape(50, 50), cmap=cm.Greys_r)\n",
    "plt.title(\"Mean-Subtracted Training Face\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Mean subtraction for test data\n",
    "Xtest_centered = test_data - mu\n",
    "\n",
    "plt.imshow(Xtest_centered[10, :].reshape(50, 50), cmap=cm.Greys_r)\n",
    "plt.title(\"Mean-Subtracted Test Face\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "41a438801a65e153",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (e)\n",
    "\n",
    "# Compute covariance matrix C = X^T X (2500 x 2500)\n",
    "C = X_centered.T @ X_centered\n",
    "\n",
    "# Eigendecomposition\n",
    "eigvals, eigvecs = np.linalg.eigh(C)\n",
    "\n",
    "# Sort eigenpairs\n",
    "idx = np.argsort(eigvals)[::-1]\n",
    "eigvals = eigvals[idx]\n",
    "eigvecs = eigvecs[:, idx]\n",
    "\n",
    "# Normalize eigenvectors\n",
    "for i in range(eigvecs.shape[1]):\n",
    "    norm = np.linalg.norm(eigvecs[:, i])\n",
    "    if norm > 0:\n",
    "        eigvecs[:, i] = eigvecs[:, i] / norm\n",
    "\n",
    "# Select top 10 eigenfaces\n",
    "top_k = 10\n",
    "eigenfaces = eigvecs[:, :top_k].T   # shape (top_k, 2500) where row i is i-th eigenface\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(top_k):\n",
    "    ef = eigenfaces[i]\n",
    "    ef_disp = (ef - ef.min()) / (ef.max() - ef.min() + 1e-12)\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(ef_disp.reshape(50, 50), cmap=cm.Greys_r)\n",
    "    plt.title(f\"Eigenface {i+1}\")\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Top 10 Eigenfaces (from largest eigenvalues)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4e0b103ddbe4b8c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (f)\n",
    "\n",
    "def compute_eigenface_features(X_centered, Xtest_centered, eigvecs, r):\n",
    "    Vr = eigvecs[:, :r]          # select top-r eigenfaces\n",
    "    F = X_centered @ Vr          # training features\n",
    "    F_test = Xtest_centered @ Vr # test features\n",
    "    return F, F_test"
   ],
   "id": "44cb1f975019b736",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (g)\n",
    "\n",
    "def train_and_eval_logreg(F_train, y_train, F_test, y_test, solver='saga', max_iter=2000, C=1.0, n_jobs=-1):\n",
    "    base_clf = LogisticRegression(solver=solver, max_iter=max_iter, C=C, tol=1e-4)\n",
    "    clf = OneVsRestClassifier(base_clf, n_jobs=n_jobs)\n",
    "    pipe = make_pipeline(StandardScaler(), clf)\n",
    "\n",
    "    pipe.fit(F_train, y_train)\n",
    "    y_pred = pipe.predict(F_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc, pipe\n",
    "\n",
    "r = 10\n",
    "F, F_test = compute_eigenface_features(X_centered, Xtest_centered, eigvecs, r)\n",
    "\n",
    "acc, model = train_and_eval_logreg(F, train_labels, F_test, test_labels, solver='saga', max_iter=2000, C=1.0, n_jobs=-1)\n",
    "print(f\"Accuracy with r={r}: {acc*100:.2f}%\")"
   ],
   "id": "46d1f94ac9f39e0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "accuracies = []\n",
    "r_values = range(1, 201)\n",
    "for r in tqdm(r_values, desc=\"Training Logistic Regression for r values\"):\n",
    "    F, F_test = compute_eigenface_features(X_centered, Xtest_centered, eigvecs, r)\n",
    "    acc, _ = train_and_eval_logreg(F, train_labels, F_test, test_labels,\n",
    "                                   solver='saga', max_iter=2000, C=1.0, n_jobs=-1)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(r_values, np.array(accuracies)*100, marker='o', linewidth=1)\n",
    "plt.xlabel(\"Number of Eigenfaces (r)\")\n",
    "plt.ylabel(\"Test Classification Accuracy (%)\")\n",
    "plt.title(\"Eigenface Logistic Regression (One-vs-Rest)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# best result\n",
    "best_r = r_values[np.argmax(accuracies)]\n",
    "best_acc = max(accuracies)\n",
    "print(f\"Best accuracy = {best_acc*100:.2f}% at r = {best_r}\")"
   ],
   "id": "365335aaed223ac3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# (h)\n",
    "\n",
    "n_train = train_data.shape[0]\n",
    "max_r = 200\n",
    "ds = np.zeros(max_r)\n",
    "\n",
    "for r in range(1, max_r + 1):\n",
    "    Vr = eigvecs[:, :r]\n",
    "    F_r = X_centered @ Vr       # Project\n",
    "    Xrec_centered = F_r @ Vr.T  # Reconstruct centered\n",
    "    Xrec = Xrec_centered + mu   # Add mean back\n",
    "    diff = train_data - Xrec    # Compute Frobenius norm\n",
    "    frob = np.linalg.norm(diff, ord='fro')\n",
    "    ds[r-1] = frob\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1, max_r+1), ds, marker='o', markersize=3)\n",
    "plt.xlabel('Number of eigenfaces r')\n",
    "plt.ylabel(r'Frobenius distance $d_r = \\|X - X\\'\\|_F$')\n",
    "plt.title('Low-rank approximation error vs r (Frobenius norm)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for r_check in [1, 5, 10, 20, 50, 100, 200]:\n",
    "    print(f\"r={r_check:3d}  Frobenius d = {ds[r_check-1]:.4f}\")"
   ],
   "id": "f60abcb54b80da90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e21039d2af0caa19",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
