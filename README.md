# EM Algorithm Implementation for Old Faithful Geyser Data

## CS5785 Homework 3 - Problem 2

This repository contains a complete implementation of the EM algorithm for fitting a bimodal Gaussian Mixture Model to the Old Faithful geyser dataset.

## ğŸ“ Project Structure

```
AML_HW3/
â”œâ”€â”€ ğŸ“„ AML_HW_3_2025_FINAL.pdf          # Assignment PDF
â”œâ”€â”€ ğŸ em_algorithm_complete.py         # Complete EM algorithm implementation
â”œâ”€â”€ ğŸ““ EM_Algorithm_Implementation.ipynb # Main Jupyter notebook
â”œâ”€â”€ ğŸ“„ EM_Algorithm_Implementation.pdf   # Notebook export
â”œâ”€â”€ ğŸ“ HW3-2/                           # Additional notebook version
â”‚   â””â”€â”€ ğŸ““ EM_Algorithm_Implementation.ipynb
â”œâ”€â”€ ğŸ“ images/                          # Generated visualizations
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ em_results.png              # EM clustering results
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ em_vs_kmeans.png           # EM vs K-means comparison
â”‚   â””â”€â”€ ğŸ–¼ï¸ faithful_data.png          # Original data visualization
â”œâ”€â”€ ğŸ test_em.py                      # Test script
â””â”€â”€ ğŸ“„ README.md                       # This file
```

## ğŸš€ Quick Start

### Running the Complete Implementation
```bash
python3 em_algorithm_complete.py
```

### Using the Jupyter Notebook
```bash
jupyter notebook EM_Algorithm_Implementation.ipynb
```

### Running Tests
```bash
python3 test_em.py
```

## ğŸ“‹ Problem Requirements (40 pts total)

### 1. Data Loading and Visualization (2 pts)
- Parse Old Faithful geyser data as 2D feature vectors
- Plot the data points on a 2D plane

### 2. E-step Formula (3 pts)
**Formula:** P(z=k|x) = P(z=k,x) / P(x) = P(x|z=k) * P(z=k) / Î£_l P(x|z=l) * P(z=l)

This computes the posterior probability that data point x belongs to cluster k.

### 3. M-step Formulas (5 pts)
**Mean:** Î¼_k = Î£_i r_ik * x_i / Î£_i r_ik
**Covariance:** Î£_k = Î£_i r_ik * (x_i - Î¼_k)(x_i - Î¼_k)^T / Î£_i r_ik
**Weights:** Ï†_k = Î£_i r_ik / n

Where r_ik = P(z_i = k | x_i) is the responsibility of cluster k for data point i.

### 4. EM Algorithm Implementation (25 pts)

#### 4.1 Implementation from Scratch (10 pts)
- Complete EM algorithm implementation using numpy
- Diagonal covariance assumption as suggested in the problem
- Random parameter initialization

#### 4.2 Termination Criterion (5 pts)
**Chosen criterion:** Log-likelihood convergence with tolerance 1e-6
- Algorithm stops when |L(t) - L(t-1)| < tolerance
- Ensures convergence to a local optimum
- Standard and robust convergence criterion

#### 4.3 Mean Vector Trajectories (10 pts)
- Plot trajectories of Î¼â‚ and Î¼â‚‚ during EM iterations
- Visualize how cluster centers evolve during optimization
- Show convergence behavior

### 5. Comparison with K-means (5 pts)
- Compare EM results with K-means clustering
- Analyze differences between soft and hard clustering
- Discuss cluster shape assumptions

## âœ¨ Key Features

### ğŸ”¬ EM Algorithm Implementation
- **ğŸ¯ Soft Clustering:** Provides probabilistic cluster assignments
- **ğŸ“ Diagonal Covariance:** Assumes Î£_k = diag(ÏƒÂ²_1, ÏƒÂ²_2, ..., ÏƒÂ²_d)
- **ğŸ”„ Convergence Detection:** Log-likelihood-based termination
- **ğŸ“ˆ Trajectory Tracking:** Records mean vector evolution

### ğŸ“Š Visualization Features
- **ğŸ“ˆ Original Data Plot:** Scatter plot of Old Faithful geyser data
- **ğŸ¨ EM Clustering Results:** Probabilistic cluster assignments
- **ğŸ“‰ Log-likelihood Convergence:** Iteration vs likelihood plot
- **ğŸ”„ Mean Vector Trajectories:** Evolution of cluster centers
- **ğŸ¯ Cluster Assignment Probabilities:** Soft clustering visualization
- **âš–ï¸ EM vs K-means Comparison:** Side-by-side clustering comparison

## ğŸ“Š Results

The implementation successfully:

### ğŸ“ˆ Dataset Processing
- **ğŸ“Š Data Points:** Loads 272 observations from Old Faithful geyser
- **âš¡ Convergence:** Converges in 8 iterations with tolerance 1e-6
- **ğŸ¯ Clusters Identified:** Two distinct eruption patterns

### ğŸ” Cluster Analysis
- **ğŸŒ‹ Cluster 1:** Short eruptions (~2.04 min) with short waiting times (~54.5 min)
- **ğŸŒ‹ Cluster 2:** Long eruptions (~4.29 min) with long waiting times (~80.0 min)
- **ğŸ“Š Probabilistic Assignments:** Soft clustering provides probability distributions

### ğŸ“¸ Generated Visualizations
All plots are saved in the `images/` folder:
- `faithful_data.png` - Original dataset visualization
- `em_results.png` - EM clustering results with probabilistic assignments
- `em_vs_kmeans.png` - Comparison between EM and K-means algorithms

## ğŸ” Analysis

### âš–ï¸ EM vs K-means Comparison

| Aspect | EM Algorithm | K-means |
|--------|-------------|---------|
| **ğŸ¯ Assignment Type** | Soft (probabilistic) | Hard (deterministic) |
| **ğŸ“ Cluster Shape** | Elliptical (diagonal covariance) | Spherical |
| **ğŸ“Š Information** | Detailed probability distributions | Binary assignments |
| **ğŸ”„ Flexibility** | Models complex cluster shapes | Assumes spherical clusters |

### ğŸ¯ Key Findings
1. **ğŸ² Soft vs Hard Clustering:** EM provides probabilistic assignments, K-means provides hard assignments
2. **ğŸ“ Cluster Shapes:** EM can model elliptical clusters, K-means assumes spherical clusters  
3. **ğŸ“Š Results:** Both methods give similar results for this dataset due to well-separated, roughly spherical clusters
4. **ğŸ”§ Flexibility:** EM provides more detailed probabilistic information and can model complex cluster shapes

## ğŸ› ï¸ Dependencies

| Package | Purpose |
|---------|---------|
| **numpy** | Numerical computations and array operations |
| **matplotlib** | Data visualization and plotting |
| **scipy** | Scientific computing utilities |
| **scikit-learn** | Machine learning algorithms (K-means comparison) |

## ğŸ“¦ Installation

```bash
pip install numpy matplotlib scipy scikit-learn
```

## ğŸ¯ Usage Examples

### ğŸ“Š Running the Complete Implementation
```bash
python3 em_algorithm_complete.py
```
*Generates all visualizations and saves them to the `images/` folder*

### ğŸ““ Interactive Jupyter Notebook
```bash
jupyter notebook EM_Algorithm_Implementation.ipynb
```
*Provides step-by-step analysis with interactive plots*

### ğŸ§ª Running Tests
```bash
python3 test_em.py
```
*Validates the EM algorithm implementation*

## ğŸ“Š Data Source

The Old Faithful geyser data is sourced from:
**ğŸ”— [CMU Statistics Data Archive](https://www.stat.cmu.edu/~larry/all-of-statistics/=data/faithful.dat)**

### ğŸ“ˆ Dataset Characteristics
- **ğŸ“Š Size:** 272 observations
- **ğŸ“ Features:** 2D feature vectors
  - **â±ï¸ Eruption Duration:** Time in minutes
  - **â³ Waiting Time:** Time to next eruption in minutes
- **ğŸ¯ Purpose:** Demonstrate bimodal clustering patterns

## ğŸ“š References

- **Hardle, W.** (1991) Smoothing Techniques with Implementation in S. New York: Springer.
- **Azzalini, A. and Bowman, A. W.** (1990). A look at some data on the Old Faithful geyser. Applied Statistics 39, 357-365.

---

## ğŸ“ License

This project is part of CS5785 Applied Machine Learning coursework at Cornell University.

## ğŸ‘¨â€ğŸ’» Author

**Student:** sosadennis39-debug  
**Course:** CS5785 Applied Machine Learning  
**Assignment:** Homework 3 - Problem 2
